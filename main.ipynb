{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-31\n",
      "2024-08-30\n",
      "2024-08-30\n",
      "['BSBK', 'BDKR', 'TOBA', 'ATLA', 'BCAP', 'ANTM', 'BBRI', 'INET', 'PTRO', 'BREN', 'PNLF', 'WIKA', 'BRPT', 'BTEK', 'APEX', 'PANI', 'BBCA', 'TLKM', 'PSAB', 'GOTO']\n",
      "['ABMM', 'SIDO', 'SSIA', 'BMRI', 'AHAP', 'NEST', 'GEMS', 'PGAS', 'MDKA', 'LEAD', 'ADRO', 'CUAN', 'ASII', 'SMRA', 'PTBA', 'SURI', 'TPIA', 'IMJS', 'MNCN', 'ESSA']\n",
      "['FILM', 'BRIS', 'TNCA', 'AMMN', 'INDX', 'UNTR', 'SRTG', 'BBNI', 'BBRM', 'ADMR', 'NISP', 'PART', 'FIRE', 'KLBF', 'WIFI', 'ISAT', 'MEDC', 'PWON', 'JPFA', 'CPIN']\n",
      "['INKP', 'UNVR', 'ARTO', 'NZIA', 'INDF', 'ELSA', 'PNBN', 'PSDN', 'GJTL', 'INCO', 'TSPC', 'BSDE', 'ERAA', 'RUIS', 'PGEO', 'GRIA', 'SMIL', 'CMRY', 'CTRA', 'HELI']\n",
      "['OASA', 'HRUM', 'AMRT', 'MKAP', 'MEJA', 'SATU', 'OKAS', 'SMGR', 'MSJA', 'BSSR', 'ADHI', 'DEWI', 'VISI', 'BUMI', 'PTPP', 'AYAM', 'SILO', 'ICBP', 'ASRI', 'SMGA']\n",
      "['BOGA', 'CHEM', 'EURO', 'ITMG', 'BBKP', 'ACES', 'INDY', 'CAMP', 'BBTN', 'MAPA', 'DSNG', 'MAPI', 'AVIA', 'SMDR', 'EXCL', 'ELPI', 'BBYB', 'MBMA', 'TGUK', 'MSKY']\n",
      "['AKRA', 'LMAX', 'MARK', 'CYBR', 'BABP', 'MPOW', 'DATA', 'GULA', 'UNTD', 'MIKA', 'JKON', 'TOWR', 'HATM', 'BUKA', 'BIPI', 'AUTO', 'DILD', 'ERAL', 'TINS', 'GZCO']\n",
      "['DOOH', 'INTP', 'AGRO', 'DSSA', 'MTEL', 'BNGA', 'DMAS', 'BRMS', 'BEER', 'STAA', 'CFIN', 'BTPS', 'IMAS', 'SICO', 'NICE', 'TOTL', 'HMSP', 'BNLI', 'HEAL', 'PPRI']\n",
      "['TMAS', 'UNIQ', 'MPMX', 'LPPF', 'INTD', 'NICL', 'TCPI', 'KKGI', 'WTON', 'SCMA', 'TAXI', 'CBPE', 'ARII', 'CLEO', 'RSCH', 'JTPE', 'MYOR', 'SAPX', 'NCKL', 'HUMI']\n",
      "['ENRG', 'MBAP', 'ASSA', 'MLPL', 'DOID', 'KIJA', 'PNBS', 'IOTF', 'APLN', 'JSMR', 'EMTK', 'CMNT', 'CITY', 'GGRM', 'BYAN', 'BNBA', 'TPMA', 'ARKO', 'BFIN', 'RALS']\n",
      "['APIC', 'LUCK', 'AGAR', 'UANG', 'PYFA', 'ULTJ', 'TKIM', 'BNII', 'ASPI', 'MSTI', 'IATA', 'VKTR', 'BIKE', 'SMSM', 'CASA', 'RAJA', 'IBOS', 'BJTM', 'FREN', 'HRTA']\n",
      "['TAPG', 'MIDI', 'PNIN', 'BHAT', 'KAEF', 'BIRD', 'BJBR', 'BLES', 'GOLF', 'TUGU', 'MCAS', 'DART', 'MANG', 'ISEA', 'SWID', 'WEGE', 'PNGO', 'BMTR', 'LABS', 'KJEN']\n",
      "['WIIM', 'AIMS', 'SSMS', 'TBIG', 'MAIN', 'PDPP', 'BAPA', 'BEBS', 'TRUK', 'WEHA', 'VTNY', 'MHKI', 'KPIG', 'BGTG', 'BELL', 'WIDI', 'DYAN', 'VICO', 'MTDL', 'SMKM']\n",
      "['MPPA', 'LPKR', 'ISAP', 'DOSS', 'HDFA', 'PEGE', 'DRMA', 'MAHA', 'KEEN', 'RCCC', 'BANK', 'DGNS', 'KRAS', 'HEXA', 'PSSI', 'AREA', 'POWR', 'NASI', 'WINS', 'MMIX']\n",
      "['COCO', 'KLAS', 'LSIP', 'OILS', 'JAWA', 'WIRG', 'MLPT', 'ACST', 'ELTY', 'PMMP', 'IMPC', 'PRDA', 'BEST', 'CNMA', 'IRRA', 'RMKE', 'MTMH', 'IKBI', 'MSIN', 'CGAS']\n",
      "['SUNI', 'TRIN', 'RAAM', 'SPTO', 'BHIT', 'MGRO', 'SGER', 'RELF', 'JARR', 'BDMN', 'SMBR', 'ANJT', 'PANS', 'DEWA', 'BESS', 'ASLC', 'HOKI', 'AALI', 'RMKO', 'SOCI']\n",
      "['SNLK', 'WINR', 'PUDP', 'PTIS', 'RIGS', 'ISSP', 'ADCP', 'DIVA', 'PTMP', 'PALM', 'BBHI', 'CARS', 'DGIK', 'CHIP', 'ARCI', 'PRIM', 'BMBL', 'HILL', 'DKFT', 'ZBRA']\n",
      "['WOOD', 'GPRA', 'TRON', 'NSSS', 'ERTX', 'PAMG', 'LTLS', 'ZATA', 'BEKS', 'MCOR', 'HALO', 'JAYA', 'KOCI', 'SAME', 'TEBE', 'KOBX', 'KOKA', 'WINE', 'BATR', 'GUNA']\n",
      "['IRSX', 'AKSI', 'GIAA', 'IPTV', 'TAMU', 'BSML', 'ANDI', 'GPSO', 'POLU', 'PICO', 'DMMX', 'MAYA', 'MLIA', 'PTPS', 'WSBP', 'NICK', 'TOTO', 'OPMS', 'BIMA', 'NELY']\n",
      "['SMDM', 'BVIC', 'SKLT', 'TOSK', 'PPRO', 'BPII', 'CASS', 'ASDM', 'RICY', 'FWCT', 'DLTA', 'BMHS', 'FUJI', 'ROTI', 'MPIX', 'WMUU', 'SPMA', 'ELIT', 'CARE', 'KOTA']\n",
      "['GTBO', 'CRAB', 'PBSA', 'SIMP', 'OMED', 'CNKO', 'AISA', 'IPCC', 'PEVE', 'SLIS', 'GOLD', 'HAIS', 'PBID', 'MBTO', 'KING', 'SRSN', 'MPXL', 'HYGN', 'CMNP', 'ASGR']\n",
      "['FOLK', 'MDLN', 'GOOD', 'INPC', 'EAST', 'PPRE', 'AEGS', 'ALDO', 'KREN', 'JGLE', 'CPRO', 'TOOL', 'PJAA', 'URBN', 'KUAS', 'UCID', 'DNAR', 'DSFI', 'NAYZ', 'GRPH']\n",
      "['BMSR', 'OLIV', 'BAIK', 'COAL', 'ACRO', 'ARNA', 'AXIO', 'HADE', 'UFOE', 'KICI', 'MRAT', 'MDRN', 'BPFI', 'SOUL', 'AMMS', 'ATIC', 'DADA', 'NRCA', 'SMAR', 'EMDE']\n",
      "['ESTA', 'AWAN', 'TELE', 'ADMF', 'BINO', 'TBLA', 'BOLT', 'LAND', 'ASMI', 'ATAP', 'ALII', 'TLDN', 'MOLI', 'SRAJ', 'MIRA', 'AMAR', 'OBMD', 'MMLP', 'BCIP', 'MCOL']\n",
      "['SMMT', 'WOWS', 'SMLE', 'AGRS', 'KBAG', 'WGSH', 'BABY', 'AGII', 'VINS', 'SDPC', 'BUAH', 'KRYA', 'KMDS', 'MENN', 'TIRT', 'KBLM', 'PGLI', 'RGAS', 'WAPO', 'LPGI']\n",
      "['SOLA', 'PADA', 'MUTU', 'PURI', 'INPS', 'CSRA', 'ABBA', 'SULI', 'IPPE', 'EKAD', 'GWSA', 'STTP', 'SMCB', 'INCI', 'FUTR', 'NETV', 'HDIT', 'BKSL', 'IKAI', 'LINK']\n",
      "['JRPT', 'DFAM', 'BWPT', 'CAKK', 'PURA', 'PMJS', 'MSIE', 'PBRX', 'INDS', 'MREI', 'GTRA', 'KARW', 'MYOH', 'NINE', 'PACK', 'LUCY', 'MKTR', 'LIVE', 'KETR', 'NOBU']\n",
      "['IPCM', 'HAJJ', 'TAYS', 'NIKL', 'TFAS', 'CSIS', 'BNBR', 'KONI', 'TRIS', 'CLPI', 'BAJA', 'MAXI', 'PGJO', 'BAUT', 'RAFI', 'SBMA', 'SAGE', 'BOBA', 'CASH', 'BELI']\n",
      "['MARI', 'FPNI', 'TARA', 'REAL', 'KBLI', 'BLTA', 'MTWI', 'JATI', 'VOKS', 'GMTD', 'INDR', 'LPCK', 'SOTS', 'MTLA', 'ASLI', 'LAJU', 'SPRE', 'AMAN', 'TRJA', 'INDO']\n",
      "['INDO', 'TRJA', 'SFAN', 'GDST', 'PANR', 'LOPI', 'MLBI', 'BAPI', 'BINA', 'BACA', 'SMMA', 'MBSS', 'UVCR', 'JAST', 'MERK', 'SONA', 'PPGL', 'LFLO', 'EDGE', 'MKPI']\n",
      "['AMFG', 'IKPM', 'PIPA', 'TGRA', 'PORT', 'BOLA', 'LPPS', 'PTPW', 'ALTO', 'ITIC', 'CEKA', 'PTDU', 'RUNS', 'SDRA', 'CBRE', 'BTPN', 'PTSN', 'DVLA', 'SKRN', 'BPTR']\n",
      "['TRUE', 'BPTR', 'BAYU', 'MDKI', 'FITT', 'HRME', 'BATA', 'NANO', 'LPIN', 'MITI', 'EPAC', 'WOMF', 'ARKA', 'ADMG', 'ALKA', 'IFII', 'TIRA', 'BBSS', 'HOMI', 'HBAT']\n",
      "['PEHA', 'GTSI', 'IPOL', 'BUDI', 'ASHA', 'PSGO', 'SAMF', 'DPUM', 'GSMF', 'KLIN', 'PSKT', 'DIGI', 'SMKL', 'ASRM', 'IBFN', 'MEGA', 'AMOR', 'KIAS', 'NFCX', 'ARGO']\n",
      "['GRPM', 'ARGO', 'VRNA', 'ADES', 'CENT', 'NASA', 'INOV', 'YULE', 'KEJU', 'FORU', 'ESTI', 'YELO', 'SEMA', 'CMPP', 'TRIM', 'BIPP', 'BISI', 'IDPR', 'MTPS', 'CBUT']\n",
      "['CBUT', 'IDPR', 'TYRE', 'IKAN', 'AMAG', 'HOPE', 'IDEA', 'APII', 'BEEF', 'RISE', 'INCF', 'BSIM', 'UNIC', 'ECII', 'ESIP', 'ICON', 'SQMI', 'RODA', 'CANI', 'ZYRX']\n",
      "['TBMS', 'BKDP', 'NATO', 'APLI', 'EPMT', 'VICI', 'ZYRX', 'BUKK', 'SCCO', 'CSAP', 'TRGU', 'POLA', 'CCSI', 'GGRP', 'SAFE', 'DEPO', 'STRK', 'HITS', 'NIRO', 'SGRO']\n",
      "['SGRO', 'GHON', 'BLUE', 'SDMU', 'JIHD', 'LPLI', 'NPGF', 'BKSW', 'INPP', 'ENZO', 'LAPD', 'PLAN', 'PDES', 'TAMA', 'SKBM', 'AKKU', 'BCIC', 'MFIN', 'UDNG', 'LCKM']\n",
      "['LCKM', 'PADI', 'PZZA', 'GLVA', 'DAYA', 'INAI', 'BALI', 'CINT', 'CRSN', 'TRST', 'FAPA', 'DUTI', 'KIOS', 'FISH', 'AYLS', 'MORA', 'RANC', 'AKPI', 'BUVA', 'INTA']\n",
      "['KMTR', 'AKPI', 'DPNS', 'FMII', 'PTSP', 'TALF', 'JECC', 'RSGK', 'PKPK', 'MTFN', 'KOPI', 'KBLV', 'BTON', 'PRAY', 'DNET', 'BRAM', 'ENAK', 'CITA', 'TRUS', 'DCII']\n",
      "['ENAK', 'DCII', 'MEDS', 'STAR', 'ALMI', 'IPAC', 'AMIN', 'SIPD', 'SOHO', 'NTBK', 'SCNP', 'PGUN', 'SOFA', 'POLY', 'MAPB', 'HERO', 'ARTA', 'KKES', 'BBMD', 'MTSM']\n",
      "['FAST', 'FLMC', 'SSTM', 'BBSI', 'BLTZ', 'MGNA', 'IGAR', 'RONY', 'KDTN', 'BRNA', 'IFSH', 'LION', 'DMND', 'TGKA', 'DWGL', 'MINA', 'INRU', 'PNSE', 'TIFA', 'SOSS']\n",
      "['MFMI', 'SURE', 'PCAR', 'TIFA', 'BMAS', 'PNSE', 'GLOB', 'TCID', 'UNSP', 'BBLD', 'ROCK', 'LMSH', 'MYTX', 'MICE', 'MPRO', 'GEMA', 'LMPI', 'BIKA', 'LCGP', 'LMAS']\n",
      "['CTBN', 'KPAL', 'KPAS', 'LIFE', 'JSPT', 'KAYU', 'ARTI', 'JMAS', 'COWL', 'ASBI', 'BIKA', 'KDSI', 'CPRI', 'JSKY', 'LABA', 'DEFI', 'KINO', 'LMPI', 'LMAS', 'DEAL']\n",
      "['SWAT', 'SINI', 'SUPR', 'KPAL', 'SUGI', 'SMRU', 'JSKY', 'JSPT', 'KRAH', 'KPAS', 'DEAL', 'TFCO', 'CSMI', 'CTBN', 'TECH', 'KINO', 'TDPM', 'KDSI', 'KBRI', 'KAYU']\n",
      "['ARTI', 'HKMU', 'HDTX', 'RIMO', 'SUPR', 'KDSI', 'LIFE', 'BIKA', 'LCGP', 'CNTB', 'TOPS', 'POSA', 'HOME', 'LABA', 'TMPO', 'CNTX', 'KRAH', 'KPAS', 'SKYB', 'KPAL']\n",
      "['SKYB', 'KAYU', 'PLIN', 'TOYS', 'KBRI', 'KDSI', 'TRAM', 'TRIL', 'PLAS', 'JSPT', 'CPRI', 'CLAY', 'CNTB', 'MTRA', 'CNTX', 'COWL', 'JMAS', 'BIKA', 'JSKY', 'TMPO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BBCA.JK: No price data found, symbol may be delisted (period=1d)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m stock \u001b[38;5;241m=\u001b[39m yf\u001b[38;5;241m.\u001b[39mTicker(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBBCA.JK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m historical_data \u001b[38;5;241m=\u001b[39m stock\u001b[38;5;241m.\u001b[39mhistory(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1d\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m last_entry_datetime \u001b[38;5;241m=\u001b[39m \u001b[43mhistorical_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m current_date \u001b[38;5;241m=\u001b[39m last_entry_datetime\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(current_date)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5365\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(key) \u001b[38;5;129;01mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5363\u001b[0m     \u001b[38;5;66;03m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5364\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mcast_scalar_indexer(key)\n\u001b[1;32m-> 5365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   5368\u001b[0m     \u001b[38;5;66;03m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5369\u001b[0m     \u001b[38;5;66;03m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_slice(key)\n",
      "\u001b[1;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "def move_date(current_date):\n",
    "    url = f\"https://sahamidx.com/?view=Home&date_now={current_date}&page=1\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    h1_elements = soup.find_all('h1')\n",
    "    # print(current_date,h1_elements)\n",
    "    for h1 in h1_elements:\n",
    "        # print(h1.text)\n",
    "        if \"Sorry, no data\" in h1.text:\n",
    "            current_date = (datetime.strptime(current_date, '%Y-%m-%d') - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "            return 2, current_date\n",
    "        else:\n",
    "            return 1, current_date\n",
    "\n",
    "    # Return a default value if no \"Sorry, no data\" is found\n",
    "    return 0, current_date\n",
    "\n",
    "# Function to extract data from the given URL\n",
    "def scrape_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "    values = []\n",
    "    if table:\n",
    "        prev_value = None\n",
    "        for td in table.find_all('td'):\n",
    "            a = td.find('a', {'target': '_blank'})\n",
    "            if a:\n",
    "                current_value = a.text.strip()\n",
    "                if current_value:\n",
    "                    if current_value != prev_value:\n",
    "                        values.append(current_value)\n",
    "                    prev_value = current_value\n",
    "    return values\n",
    "\n",
    "all_values = []\n",
    "check_dates = 2\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "while check_dates == 2:\n",
    "    check_dates, current_date = move_date(current_date)\n",
    "    print(current_date)\n",
    "\n",
    "# Iterate pages\n",
    "for iter in range(1, 47):\n",
    "    url = f\"https://sahamidx.com/?view=Home&date_now={current_date}&page={iter}\"\n",
    "\n",
    "    # Scrape data from the current URL\n",
    "    values = scrape_data(url)\n",
    "    print(values)\n",
    "\n",
    "    # Add the values to the list\n",
    "    all_values.extend(values)\n",
    "\n",
    "# print(all_values)\n",
    "stock = yf.Ticker(\"BBCA.JK\")\n",
    "historical_data = stock.history(period='1d')\n",
    "last_entry_datetime = historical_data.index[-1].strftime(\"%Y-%m-%d\")\n",
    "current_date = last_entry_datetime\n",
    "print(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Mount Google Drive\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import math as m\n",
    "from git import Repo\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration from environment variables\n",
    "GITHUB_REPO = os.getenv('_GITHUB_REPO')\n",
    "GITHUB_TOKEN = os.getenv('_GITHUB_TOKEN')\n",
    "BRANCH_NAME = os.getenv('_BRANCH_NAME')\n",
    "\n",
    "# Create a temporary local repository for working with files\n",
    "TEMP_DIR = '/tmp/repo'\n",
    "if not os.path.exists(TEMP_DIR):\n",
    "    Repo.clone_from(f'https://github.com/{GITHUB_REPO}.git', TEMP_DIR, branch=BRANCH_NAME)\n",
    "repo = Repo(TEMP_DIR)\n",
    "\n",
    "def push_to_github(filename, content):\n",
    "    \"\"\" Push a file to GitHub repository. \"\"\"\n",
    "    file_path = os.path.join(TEMP_DIR, filename)\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "    repo.index.add([file_path])\n",
    "    repo.index.commit(f'Update {filename}')\n",
    "    origin = repo.remote(name='origin')\n",
    "    origin.push()\n",
    "\n",
    "def create_excel_and_debug_files():\n",
    "    \"\"\" Create the necessary files and push them to GitHub. \"\"\"\n",
    "    current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "    excel_filename = f\"stock_data_{current_date}.xlsx\"\n",
    "    debug_filename = f\"debug_stock_scrapper_{current_date}.txt\"\n",
    "\n",
    "    # Create empty files\n",
    "    df_empty = pd.DataFrame()\n",
    "    df_empty.to_excel(os.path.join(TEMP_DIR, excel_filename), index=False)\n",
    "    \n",
    "    with open(os.path.join(TEMP_DIR, debug_filename), 'w') as debug_file:\n",
    "        debug_file.write(\"Debug Log - Stock Scrapper\\n\\n\")\n",
    "\n",
    "    # Push files to GitHub\n",
    "    push_to_github(excel_filename, '')\n",
    "    push_to_github(debug_filename, '')\n",
    "\n",
    "create_excel_and_debug_files()\n",
    "\n",
    "# Your stock analysis code here...\n",
    "import yfinance as yf\n",
    "import math as m\n",
    "\n",
    "def get_perc_change(n_days, history_cls):\n",
    "    temp_array = history_cls[:n_days]\n",
    "    first_item = temp_array[0]\n",
    "    last_item = temp_array[-1]\n",
    "    perc_change = (first_item - last_item) / last_item * 100\n",
    "    return perc_change\n",
    "\n",
    "def get_volas(n_days, history_cls):\n",
    "    temp_price = history_cls[:n_days]\n",
    "    avg_price = sum(temp_price) / n_days\n",
    "    diff_cls = [temp_price[i] - avg_price for i in range(n_days)]\n",
    "    diff_cls = [diff**2 for diff in diff_cls]\n",
    "    variance = sum(diff_cls) / n_days\n",
    "    std_dev = m.sqrt(variance)\n",
    "    return std_dev\n",
    "\n",
    "def get_avg_vol(n_days, history_vol):\n",
    "    return sum(history_vol[:n_days]) / n_days\n",
    "\n",
    "def get_ma(n_days, history_cls):\n",
    "    return sum(history_cls[:n_days]) / n_days\n",
    "\n",
    "def calculate_display_ma(ma5, ma10, ma20, ma50, ma100, ma200, stock):\n",
    "    symbols = []\n",
    "    output_const = 0\n",
    "    for ma in [ma5, ma10, ma20, ma50, ma100, ma200]:\n",
    "        if stock > ma:\n",
    "            symbols.append(\">\")\n",
    "            output_const += 1\n",
    "        elif stock == ma:\n",
    "            symbols.append(\"=\")\n",
    "        else:\n",
    "            symbols.append(\"<\")\n",
    "            output_const -= 1\n",
    "    return symbols, output_const\n",
    "\n",
    "def analyze_bound_stock(n_days, history_cls, history_vol):\n",
    "    output_const = 0.0\n",
    "    i = 0\n",
    "    is_avg_check = False\n",
    "    multiplier = n_days / 2\n",
    "    temp_price = history_cls[:n_days]\n",
    "    temp_vol = history_vol[:n_days]\n",
    "    avg_price = sum(temp_price) / n_days\n",
    "    avg_vol = sum(temp_vol) / n_days\n",
    "    upper_bound_avg_vol = avg_vol + avg_vol / multiplier\n",
    "    lower_bound_avg_vol = avg_vol - avg_vol / multiplier\n",
    "    lower_bound = avg_price - (avg_price / multiplier)\n",
    "    while not is_avg_check and i < n_days:\n",
    "        is_low_vol = lower_bound_avg_vol < history_vol[i] < upper_bound_avg_vol\n",
    "        if lower_bound < history_cls[i+1] and is_low_vol:\n",
    "            i += 1\n",
    "            output_const += 1\n",
    "        else:\n",
    "            is_avg_check = True\n",
    "    return output_const\n",
    "\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "excel_filename = f\"stock_data_{current_date}.xlsx\"\n",
    "debug_filename = f\"debug_stock_scrapper_{current_date}.txt\"\n",
    "df_empty = pd.DataFrame()\n",
    "df_empty.to_excel(os.path.join(TEMP_DIR, excel_filename), index=False)\n",
    "with open(os.path.join(TEMP_DIR, debug_filename), 'w') as debug_file:\n",
    "    debug_file.write(\"Debug Log - Stock Scrapper\\n\\n\")\n",
    "\n",
    "header = [\n",
    "    'Stock', 'Market Cap and Buy Analysis', 'Buy Analysis', 'Volume Analysis Result',\n",
    "    'Volume Analysis 5 Days', 'Volume Analysis 20 Days', 'Volume Analysis 50 Days',\n",
    "    'MA Analysis', 'MA5', 'MA5 Symbol', 'MA10', 'MA10 Symbol', 'MA20', 'MA20 Symbol',\n",
    "    'MA50', 'MA50 Symbol', 'MA100', 'MA100 Symbol', 'MA200', 'MA200 Symbol',\n",
    "    '3D Change%', '5D Change%', '20D Change%', 'Yesterday Closing Price', 'Current Price',\n",
    "    'Volatility in 3 Day', 'Volatility in 5 Days', 'Volatility in 20 Days',\n",
    "    'Market Cap Value', 'Volume Average in 5 Days', 'Volume Average in 20 Days',\n",
    "    'Volume Average in 50 Days', 'Volume Average in 100 Days',\n",
    "]\n",
    "\n",
    "with pd.ExcelWriter(os.path.join(TEMP_DIR, excel_filename), engine='openpyxl') as writer:\n",
    "    pd.DataFrame(columns=header).to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "stocks = [item + \".JK\" for item in all_values]\n",
    "\n",
    "for i, stock in enumerate(stocks, start=1):\n",
    "    for period in ['max', 'ytd', '3mo', '1mo']:\n",
    "        try:\n",
    "            history = yf.download(stock, period=period)\n",
    "            if len(history) == 0:\n",
    "                raise ValueError(f\"No data for {stock} with period {period}\")\n",
    "\n",
    "            stock_data = yf.Ticker(stock)\n",
    "            info = stock_data.info\n",
    "            history_cls = history['Close'].tolist()[::-1]\n",
    "            history_vol = history['Volume'].tolist()[::-1]\n",
    "\n",
    "            perc3 = get_perc_change(3, history_cls)\n",
    "            perc5 = get_perc_change(5, history_cls)\n",
    "            perc20 = get_perc_change(20, history_cls)\n",
    "\n",
    "            vola3 = get_volas(3, history_cls)\n",
    "            vola5 = get_volas(5, history_cls)\n",
    "            vola20 = get_volas(20, history_cls)\n",
    "\n",
    "            vol5 = get_avg_vol(5, history_vol)\n",
    "            vol20 = get_avg_vol(20, history_vol)\n",
    "            vol50 = get_avg_vol(50, history_vol)\n",
    "            vol100 = get_avg_vol(100, history_vol)\n",
    "\n",
    "            ma5 = get_ma(5, history_cls)\n",
    "            ma10 = get_ma(10, history_cls)\n",
    "            ma20 = get_ma(20, history_cls)\n",
    "            ma50 = get_ma(50, history_cls)\n",
    "            ma100 = get_ma(100, history_cls)\n",
    "            ma200 = get_ma(200, history_cls)\n",
    "\n",
    "            display_ma, ma_const = calculate_display_ma(ma5, ma10, ma20, ma50, ma100, ma200, history_cls[0])\n",
    "\n",
    "            volume_const5 = analyze_bound_stock(5, history_cls, history_vol)\n",
    "            volume_const20 = analyze_bound_stock(20, history_cls, history_vol)\n",
    "            volume_const50 = analyze_bound_stock(50, history_cls, history_vol)\n",
    "            volume_analysis = (volume_const5 / 5 + volume_const20 / 20 + volume_const50 / 50) * ma_const\n",
    "            final_analysis = volume_analysis * info['marketCap'] / 1000000\n",
    "\n",
    "            stock_info = pd.DataFrame({\n",
    "                'Stock': [stock],\n",
    "                'Market Cap and Buy Analysis': [final_analysis],\n",
    "                'Buy Analysis': [volume_analysis],\n",
    "                'Volume Analysis Result': [volume_const5 + volume_const20 + volume_const50],\n",
    "                'Volume Analysis 5 Days': [volume_const5],\n",
    "                'Volume Analysis 20 Days': [volume_const20],\n",
    "                'Volume Analysis 50 Days': [volume_const50],\n",
    "                'MA Analysis': [ma_const],\n",
    "                'MA5': [ma5],\n",
    "                'MA5 Symbol': [display_ma[0]],\n",
    "                'MA10': [ma10],\n",
    "                'MA10 Symbol': [display_ma[1]],\n",
    "                'MA20': [ma20],\n",
    "                'MA20 Symbol': [display_ma[2]],\n",
    "                'MA50': [ma50],\n",
    "                'MA50 Symbol': [display_ma[3]],\n",
    "                'MA100': [ma100],\n",
    "                'MA100 Symbol': [display_ma[4]],\n",
    "                'MA200': [ma200],\n",
    "                'MA200 Symbol': [display_ma[5]],\n",
    "                '3D Change%': [perc3],\n",
    "                '5D Change%': [perc5],\n",
    "                '20D Change%': [perc20],\n",
    "                'Yesterday Closing Price': [history_cls[1]],\n",
    "                'Current Price': [history_cls[0]],\n",
    "                'Volatility in 3 Day': [vola3],\n",
    "                'Volatility in 5 Days': [vola5],\n",
    "                'Volatility in 20 Days': [vola20],\n",
    "                'Market Cap Value': [info['marketCap']],\n",
    "                'Volume Average in 5 Days': [vol5],\n",
    "                'Volume Average in 20 Days': [vol20],\n",
    "                'Volume Average in 50 Days': [vol50],\n",
    "                'Volume Average in 100 Days': [vol100],\n",
    "            })\n",
    "\n",
    "            # Save data to the local repository\n",
    "            with pd.ExcelWriter(os.path.join(TEMP_DIR, excel_filename), engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "                stock_info.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "            with open(os.path.join(TEMP_DIR, debug_filename), 'a') as debug_file:\n",
    "                debug_file.write(f\"Successfully processed {stock} with period {period}.\\n\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            with open(os.path.join(TEMP_DIR, debug_filename), 'a') as debug_file:\n",
    "                debug_file.write(f\"Error processing {stock} with period {period}: {str(e)}\\n\")\n",
    "\n",
    "    print(\"done:\", i, \"|\", stock)\n",
    "\n",
    "print(\"#######all done#####\")\n",
    "\n",
    "# Push the final Excel and debug files to GitHub\n",
    "with open(os.path.join(TEMP_DIR, excel_filename), 'rb') as f:\n",
    "    content = f.read()\n",
    "    response = requests.put(\n",
    "        f'https://api.github.com/repos/{GITHUB_REPO}/contents/{excel_filename}',\n",
    "        headers={\n",
    "            'Authorization': f'token {GITHUB_TOKEN}',\n",
    "            'Content-Type': 'application/vnd.github.v3+json'\n",
    "        },\n",
    "        json={\n",
    "            'message': 'Update stock data',\n",
    "            'content': content.encode('base64'),\n",
    "            'branch': BRANCH_NAME\n",
    "        }\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "\n",
    "with open(os.path.join(TEMP_DIR, debug_filename), 'rb') as f:\n",
    "    content = f.read()\n",
    "    response = requests.put(\n",
    "        f'https://api.github.com/repos/{GITHUB_REPO}/contents/{debug_filename}',\n",
    "        headers={\n",
    "            'Authorization': f'token {GITHUB_TOKEN}',\n",
    "            'Content-Type': 'application/vnd.github.v3+json'\n",
    "        },\n",
    "        json={\n",
    "            'message': 'Update debug log',\n",
    "            'content': content.encode('base64'),\n",
    "            'branch': BRANCH_NAME\n",
    "        }\n",
    "    )\n",
    "    response.raise_for_status()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
